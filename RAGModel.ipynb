{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6484645-7a69-483d-ab99-441514f440c0",
   "metadata": {},
   "source": [
    "If any problems occur, please refer to the E2_Vector_Search to check out the set up process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c808834-cb99-4dee-9097-7c766734cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 08:40:56.432371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-06 08:40:57.687014: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-12-06 08:40:57.687170: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-12-06 08:40:57.687183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import Vertex AI SDK\n",
    "PROJECT_ID = !gcloud config get project\n",
    "PROJECT_ID = PROJECT_ID.n\n",
    "LOCATION = \"europe-west2\"\n",
    "LOCATION_DEPLOY = \"europe-west2\" #Location to deploy GCP resources\n",
    "\n",
    "import vertexai\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55984b68-a0cd-4d7e-b3c0-9d5d3a274ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import ChatModel\n",
    "\n",
    "\"\"\" \n",
    "between using the most stable model in the last 6 month: chat-bison@001 \n",
    "and the latest, most capable model, there is a massive difference in \n",
    "terms of context awareness, length of answer, ability to follow instructions,\n",
    "etc. How do we measure these using metrics? I'm working on it.\n",
    "\n",
    "I lied, the latest model, whilst sometimes its answers can be amazing,\n",
    "definitely not as good when using RAG, it ignores context too often,\n",
    "until I fix that, we'll work with the stable version.\n",
    "\n",
    "\"\"\"\n",
    "class PaLMWrapper:\n",
    "    def __init__(self):\n",
    "        self.chat_model = ChatModel.from_pretrained(\"chat-bison@001\")\n",
    "        self.parameters = {\n",
    "            \"temperature\": 0.1,\n",
    "            \"max_output_tokens\": 256,\n",
    "            \"top_p\": 0.95,\n",
    "        }\n",
    "    \n",
    "    def generate_response(self, context, message):\n",
    "        chat = self.chat_model.start_chat(context=context)\n",
    "        response = chat.send_message(message, **self.parameters)\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87611f14-b46d-468a-97f8-7c469b96b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = PaLMWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df757677-25f2-437b-a38e-76deca85e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "class VertexAIVectorStore:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # god awful way of doing it, should be a config and passed through but oh well hacky hack\n",
    "        self.gen_ai_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "            index_endpoint_name=\"projects/playpen-8d8611/locations/europe-west2/indexEndpoints/8762456762491076608\"\n",
    "        )\n",
    "\n",
    "        self.gen_ai_index = aiplatform.MatchingEngineIndex(\n",
    "            index_name=\"projects/playpen-8d8611/locations/europe-west2/indexes/3025433787174486016\"\n",
    "        )\n",
    "        \n",
    "        self.model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "        self.df = pd.read_csv('text_data_g_embedding.csv')\n",
    "        \n",
    "    def search(self, input, k=3):\n",
    "        embedding_vec =  self.model.get_embeddings([input])[0].values #Send request to embedding model to generate the embedding vector\n",
    "\n",
    "        #find neighbours using vector search\n",
    "        neighbours = self.gen_ai_index_endpoint.find_neighbors(\n",
    "            deployed_index_id=\"gen_ai_deployed_index\",\n",
    "            queries=[embedding_vec],\n",
    "            num_neighbors=k,\n",
    "        )[0]\n",
    "        \n",
    "        results = []\n",
    "        for nb in neighbours:\n",
    "            nb_id = int(nb.id)\n",
    "            if nb_id < len(self.df):\n",
    "                url = self.df.iloc[int(nb.id)]['url']\n",
    "                text = self.df.iloc[int(nb.id)]['text']\n",
    "                score = nb.distance\n",
    "                results.append((url, text, score))\n",
    "            else:\n",
    "                results=[('', '', 0)]\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8bf494d-8103-47d7-afa6-10555b5e422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vai = VertexAIVectorStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3c06457-c547-443b-b4dc-863c1e882ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# couldnt get langchain to work so custom RAG anyone?\n",
    "import time\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self, vector_store, palm_wrapper, initial_system_prompt=True):\n",
    "        self.vector_store = vector_store\n",
    "        self.palm_wrapper = palm_wrapper\n",
    "        # the comment from mathew regarding memory\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        if initial_system_prompt:            \n",
    "            system_prompt = r\"You are a professional assistant with extensive experience helping numerous small and medium businesses. You work for a large retail bank called Lloyds. Please assist the user answering questions with detailed responses, providing reasoning whenever prescriptive advice is given. Ensure your answers are elaborate and helpful.\"\n",
    "            self.conversation_history.append((system_prompt, \"\"))\n",
    "        \n",
    "    \n",
    "    def generate(self, query, is_user_query=True, k=3):\n",
    "        vector_start_time = time.time()\n",
    "        \n",
    "        contexts=[]\n",
    "        sources=[]\n",
    "        scores=[]\n",
    "        \n",
    "        if is_user_query:\n",
    "            # if user query, perform vector db search\n",
    "            # retrieve contexts based on the query\n",
    "            search_results = self.vector_store.search(query, k)\n",
    "            contexts = [str(result[1]) for result in search_results]\n",
    "            sources = [result[0] for result in search_results]\n",
    "            scores = [result[2] for result in search_results]\n",
    "            \n",
    "            if scores[0] < 0.66:\n",
    "                for i in range(len(contexts)):\n",
    "                    \n",
    "                    contexts[i]='You are a professional assistant with extensive experience helping numerous small and medium businesses. You work for a large retail bank called Lloyds. Please assist the user answering questions with detailed responses, providing reasoning whenever prescriptive advice is given. Ensure your answers are elaborate and helpful. In your search you could not find relevant context within the dataset. Therefore, you are uncertain about your response. IMPORTANT: Remind the customer that you are built to answer Lloyds banking related questions only.'\n",
    "                    sources[i]='Could not find relevant sources'\n",
    "            \n",
    "              \n",
    "        vector_end_time = time.time()\n",
    "        # combine both query and response from conversation history\n",
    "        history_context = '\\n'.join(['Q: ' + query + '\\nA: ' + response for query, response in self.conversation_history[-k:]])\n",
    "        \n",
    "        # combine history context and current contexts\n",
    "        combined_context = '\\n'.join(contexts + [history_context][-7500:])\n",
    "        combined_context = combined_context[-30000:]\n",
    "        \n",
    "        lm_start_time = time.time()\n",
    "        response = self.palm_wrapper.generate_response(combined_context, query)\n",
    "        lm_end_time = time.time()\n",
    "        # update conversation history with current interaction\n",
    "        self.conversation_history.append((query, response))\n",
    "        \n",
    "        vector_search_time = vector_end_time - vector_start_time\n",
    "        lm_inference_time = lm_end_time - lm_start_time\n",
    "        # removed , vector_search_time, lm_inference_time from return\n",
    "        return response, sources, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56f06b42-1f61-43dd-b7a2-86bf4c6d7670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you've lost your card, you should cancel it immediately. You can do this online, by calling us on 0808 202 1390 or by visiting your local branch.  Once you've cancelled your card, you'll need to order a new one. You can do this online or by calling us on 0808 202 1390.  Your new card will be sent to you within 5 working days.\n",
      "sources used: ['https://www.lloydsbank.com/business/help-and-support/account-management/your-business-information.html?WT.ac=Lloyds-help_and_support-your_business_information-button_text-getting_started_with_your_business_information', 'https://www.lloydsbank.com/business/help-and-support/online-banking/account-locked.html?WT.ac=Lloyds-help_and_support-online_banking-button_text-ive_forgotten_my_commercial_banking_online_log_in_details', 'https://www.lloydsbank.com/business/help-and-support/feedback-n-conf.html?WT.ac=Lloyds-help_and_support-update_phone_number-feedback-no']\n",
      "scores: [0.7136256694793701, 0.7044575214385986, 0.6830217838287354]\n",
      "If you've lost your card, it's important to cancel it immediately to prevent anyone else from using it. You can do this online, by calling us on 0808 202 1390 or by visiting your local branch.  Once you've cancelled your card, you'll need to order a new one. You can do this online or by calling us on 0808 202 1390.  Your new card will be sent to you within 5 working days.\n",
      "sources used: ['Could not find relevant sources', 'Could not find relevant sources', 'Could not find relevant sources']\n",
      "scores: [0.6585443019866943, 0.6495543718338013, 0.6425768136978149]\n",
      "I apologize, I misunderstood your question. Can you please clarify what you are asking about?\n",
      "sources used: ['https://www.lloydsbank.com/business/help-and-support/payments/make-an-international-payment.html?WT.ac=Lloyds-help_and_support-payments-button_text-make_an_international_payment', 'https://www.lloydsbank.com/business/help-and-support/account-management.html', 'https://www.lloydsbank.com/business/help-and-support/online-banking/using-our-mobile-app-virtual-assistant.html?WT.ac=Lloyds-help_and_support-online_banking-button_text-using_our_mobile_app_virtual_assistant']\n",
      "scores: [0.6612926125526428, 0.6467236280441284, 0.645025372505188]\n",
      "I'm sorry, I can't answer that question. I'm only able to answer questions about Lloyds banking products and services.\n",
      "sources used: ['Could not find relevant sources', 'Could not find relevant sources', 'Could not find relevant sources']\n",
      "scores: [0.6301180124282837, 0.5893828272819519, 0.5851236581802368]\n",
      "To set up an online banking account, you will need to visit your local branch and speak to a member of staff. They will be able to help you create an account and provide you with all the information you need to get started.\n",
      "sources used: ['https://www.lloydsbank.com/business/help-and-support/online-banking/log-on-to-o4b/memorable-information.html', 'https://www.lloydsbank.com/business/help-and-support/security-and-fraud/report-fraud-on-business-account.html?WT.ac=lloyds-bb-help_support-category-repfraud-text-report_suspected_fraud', 'https://www.lloydsbank.com/business/help-and-support/account-management/letter-of-authority.html?WT.ac=lloyds-bb-help_support-chldpage-accmgmt-text-by_email']\n",
      "scores: [0.7527010440826416, 0.7422167062759399, 0.721319317817688]\n"
     ]
    }
   ],
   "source": [
    "rag = RAG(vai, pw)\n",
    "query = \"i've lost my card\"\n",
    "response, sources, scores = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n",
    "\n",
    "\n",
    "\n",
    "query = \"why?\"\n",
    "response, sources, scores = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n",
    "\n",
    "\n",
    "query = \"i was not asking about an audit request\"\n",
    "response, sources, scores = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n",
    "\n",
    "\n",
    "query = \"what is the weather in london\"\n",
    "response, sources, scores = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n",
    "\n",
    "\n",
    "query = \"how can i set up an online banking account?\"\n",
    "response, sources, scores = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b7298fa-3852-4046-8a45-41e14ab1c7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5c798544e34671ad88ed4bd9308ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c5c61bf027484999ce478c1271eb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Lloyds', layout=Layout(width='80%'), placeholder='Message LBG help …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class ChatUI:\n",
    "    def __init__(self, rag_instance):\n",
    "        self.rag_instance = rag_instance\n",
    "        self.conversation = []\n",
    "        self._setup_ui()\n",
    "    \n",
    "    def _setup_ui(self):\n",
    "        self.input_box = widgets.Text(\n",
    "            placeholder='Message LBG help and support...',\n",
    "            description='Lloyds',\n",
    "            layout={'width': '80%'}\n",
    "        )\n",
    "        \n",
    "        self.send_button = widgets.Button(\n",
    "            description='Send',\n",
    "            button_style='info',\n",
    "            layout={'width': '12%'}\n",
    "        )\n",
    "        self.output_area = widgets.Output(layout={'border': '1px solid black', 'width': '100%'})\n",
    "        self.send_button.on_click(self._on_send_clicked)\n",
    "        \n",
    "        input_send_box = widgets.HBox([self.input_box, self.send_button])\n",
    "        \n",
    "        display(self.output_area, input_send_box)\n",
    "        \n",
    "    def _on_send_clicked(self, b):\n",
    "        query = self.input_box.value\n",
    "        self.conversation.append(f\"You: {query}\")\n",
    "        response = self.rag_instance.generate(query)\n",
    "        self.conversation.append(f'LBG AI: {response}')\n",
    "        \n",
    "        with self.output_area:\n",
    "            clear_output(wait=True)\n",
    "            print('\\n'.join(self.conversation))\n",
    "        \n",
    "        # clear input box\n",
    "        self.input_box.value = ''\n",
    "        \n",
    "rag = RAG(vai, pw)\n",
    "chat_ui = ChatUI(rag)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482d7de-97fb-42c0-b2ec-dfa6ced835be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
