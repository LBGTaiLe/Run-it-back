{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6484645-7a69-483d-ab99-441514f440c0",
   "metadata": {},
   "source": [
    "If any problems occur, please refer to the E2_Vector_Search to check out the set up process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c808834-cb99-4dee-9097-7c766734cc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 08:40:56.432371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-06 08:40:57.687014: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-12-06 08:40:57.687170: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-12-06 08:40:57.687183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import Vertex AI SDK\n",
    "PROJECT_ID = !gcloud config get project\n",
    "PROJECT_ID = PROJECT_ID.n\n",
    "LOCATION = \"europe-west2\"\n",
    "LOCATION_DEPLOY = \"europe-west2\" #Location to deploy GCP resources\n",
    "\n",
    "import vertexai\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55984b68-a0cd-4d7e-b3c0-9d5d3a274ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import ChatModel\n",
    "\n",
    "\"\"\" \n",
    "between using the most stable model in the last 6 month: chat-bison@001 \n",
    "and the latest, most capable model, there is a massive difference in \n",
    "terms of context awareness, length of answer, ability to follow instructions,\n",
    "etc. How do we measure these using metrics? I'm working on it.\n",
    "\n",
    "I lied, the latest model, whilst sometimes its answers can be amazing,\n",
    "definitely not as good when using RAG, it ignores context too often,\n",
    "until I fix that, we'll work with the stable version.\n",
    "\n",
    "\"\"\"\n",
    "class PaLMWrapper:\n",
    "    def __init__(self):\n",
    "        self.chat_model = ChatModel.from_pretrained(\"chat-bison@001\")\n",
    "        self.parameters = {\n",
    "            \"temperature\": 0.3,\n",
    "            \"max_output_tokens\": 256,\n",
    "            \"top_p\": 0.95,\n",
    "        }\n",
    "    \n",
    "    def generate_response(self, context, message):\n",
    "        chat = self.chat_model.start_chat(context=context)\n",
    "        response = chat.send_message(message, **self.parameters)\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87611f14-b46d-468a-97f8-7c469b96b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = PaLMWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df757677-25f2-437b-a38e-76deca85e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "class VertexAIVectorStore:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # god awful way of doing it, should be a config and passed through but oh well hacky hack\n",
    "        self.gen_ai_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "            index_endpoint_name=\"projects/playpen-8d8611/locations/europe-west2/indexEndpoints/8762456762491076608\"\n",
    "        )\n",
    "\n",
    "        self.gen_ai_index = aiplatform.MatchingEngineIndex(\n",
    "            index_name=\"projects/playpen-8d8611/locations/europe-west2/indexes/3025433787174486016\"\n",
    "        )\n",
    "        \n",
    "        self.model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "        self.df = pd.read_csv('text_data_g_embedding.csv')\n",
    "        \n",
    "    def search(self, input, k=3):\n",
    "        embedding_vec =  self.model.get_embeddings([input])[0].values #Send request to embedding model to generate the embedding vector\n",
    "\n",
    "        #find neighbours using vector search\n",
    "        neighbours = self.gen_ai_index_endpoint.find_neighbors(\n",
    "            deployed_index_id=\"gen_ai_deployed_index\",\n",
    "            queries=[embedding_vec],\n",
    "            num_neighbors=k,\n",
    "        )[0]\n",
    "        \n",
    "        results = []\n",
    "        for nb in neighbours:\n",
    "            nb_id = int(nb.id)\n",
    "            if nb_id < len(self.df):\n",
    "                url = self.df.iloc[int(nb.id)]['url']\n",
    "                text = self.df.iloc[int(nb.id)]['text']\n",
    "                score = nb.distance\n",
    "                results.append((url, text, score))\n",
    "            else:\n",
    "                results=[('', '', 0)]\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8bf494d-8103-47d7-afa6-10555b5e422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vai = VertexAIVectorStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c06457-c547-443b-b4dc-863c1e882ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# couldnt get langchain to work so custom RAG anyone?\n",
    "import time\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self, vector_store, palm_wrapper, initial_system_prompt=True):\n",
    "        self.vector_store = vector_store\n",
    "        self.palm_wrapper = palm_wrapper\n",
    "        # the comment from mathew regarding memory\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        if initial_system_prompt:            \n",
    "            system_prompt = r\"You are a professional assistant with extensive experience helping numerous small and medium businesses. You work for a large retail bank called Lloyds. Please assist the user answering questions with detailed responses, providing reasoning whenever prescriptive advice is given. Ensure your answers are elaborate and helpful.\"\n",
    "            self.conversation_history.append((system_prompt, \"\"))\n",
    "        \n",
    "    \n",
    "    def generate(self, query, is_user_query=True, k=3):\n",
    "        vector_start_time = time.time()\n",
    "        \n",
    "        contexts=[]\n",
    "        sources=[]\n",
    "        scores=[]\n",
    "        \n",
    "        if is_user_query:\n",
    "            # if user query, perform vector db search\n",
    "            # retrieve contexts based on the query\n",
    "            search_results = self.vector_store.search(query, k)\n",
    "            contexts = [str(result[1]) for result in search_results]\n",
    "            sources = [result[0] for result in search_results]\n",
    "            scores = [result[2] for result in search_results]\n",
    "            \n",
    "            if sum(scores)/len(scores) < 0.65:\n",
    "                for i in range(len(contexts)):\n",
    "                    \n",
    "                    contexts[i]='In your search you could not find relevant context within the dataset. Therefore, you are uncertain about your response. IMPORTANT: Remind the customer that you are built to answer Lloyds banking related questions only.'\n",
    "                    sources[i]='Could not find relevant sources'\n",
    "            \n",
    "              \n",
    "        vector_end_time = time.time()\n",
    "        # combine both query and response from conversation history\n",
    "        history_context = '\\n'.join(['Q: ' + query + '\\nA: ' + response for query, response in self.conversation_history[-k:]])\n",
    "        \n",
    "        # combine history context and current contexts\n",
    "        combined_context = '\\n'.join([history_context] + contexts)\n",
    "        combined_context = combined_context[-20000:]\n",
    "        \n",
    "        lm_start_time = time.time()\n",
    "        response = self.palm_wrapper.generate_response(combined_context, query)\n",
    "        lm_end_time = time.time()\n",
    "        # update conversation history with current interaction\n",
    "        self.conversation_history.append((query, response))\n",
    "        \n",
    "        vector_search_time = vector_end_time - vector_start_time\n",
    "        lm_inference_time = lm_end_time - lm_start_time\n",
    "        \n",
    "        return response, sources, scores, vector_search_time, lm_inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f06b42-1f61-43dd-b7a2-86bf4c6d7670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm sorry to hear that you've lost your card. Here are the steps you need to take:\n",
      "1. Â Call us onÂ  0808 202 1390 .  Lines are open 8am to 6pm Monday to Friday.  Please have your Telephony PIN with you when you call so we can identity you.\n",
      "2. Â We'll cancel your card and issue you with a new one.\n",
      "3. Â You'll need to set up a new Direct Debit mandate for any payments that are due to come out of your account.\n",
      "4. Â You'll also need to update your card details with any businesses or websites that you use your card with.\n",
      "sources used: ['https://www.lloydsbank.com/business/help-and-support/account-management/your-business-information.html?WT.ac=Lloyds-help_and_support-your_business_information-button_text-getting_started_with_your_business_information', 'https://www.lloydsbank.com/business/help-and-support/online-banking/account-locked.html?WT.ac=Lloyds-help_and_support-online_banking-button_text-ive_forgotten_my_commercial_banking_online_log_in_details', 'https://www.lloydsbank.com/business/help-and-support/feedback-n-conf.html?WT.ac=Lloyds-help_and_support-update_phone_number-feedback-no']\n",
      "scores: [0.7136256694793701, 0.7044575214385986, 0.6830217838287354]\n",
      "vector search time: 0.32883763313293457\n",
      "llm inference time: 3.3784828186035156\n",
      " A regulation called SCA (Strong Customer Authentication) has been introduced across all banks which required you to have two ways to prove it is you logging into your online banking. This can be something you are, have or know. By trusting your device you are registering it as something you have. However, if we canât identify your device as trusted, the Card & Reader becomes the way to authenticate using something you have.\n",
      "sources used: ['https://www.lloydsbank.com/business/help-and-support/payments/make-an-international-payment.html?WT.ac=Lloyds-help_and_support-payments-button_text-make_an_international_payment', 'https://www.lloydsbank.com/business/help-and-support/online-banking/deposit-cheques-in-business-mobile-banking-app.html?WT.ac=Lloyds-help_and_support-online_banking-button_text-depositing_cheques_in_the_business_mobile_app', 'https://www.lloydsbank.com/business/help-and-support/online-banking/log-on-to-o4b/trusting-your-device.html']\n",
      "scores: [0.6585443019866943, 0.6495543718338013, 0.6425768136978149]\n",
      "vector search time: 0.2411201000213623\n",
      "llm inference time: 0.9486799240112305\n",
      "I'm sorry, I misunderstood. What can I help you with?\n",
      "sources used: ['https://www.lloydsbank.com/business/help-and-support/payments/make-an-international-payment.html?WT.ac=Lloyds-help_and_support-payments-button_text-make_an_international_payment', 'https://www.lloydsbank.com/business/help-and-support/account-management.html', 'https://www.lloydsbank.com/business/help-and-support/online-banking/using-our-mobile-app-virtual-assistant.html?WT.ac=Lloyds-help_and_support-online_banking-button_text-using_our_mobile_app_virtual_assistant']\n",
      "scores: [0.6585443019866943, 0.6495543718338013, 0.6425768136978149]\n",
      "vector search time: 0.19262027740478516\n",
      "llm inference time: 0.9486799240112305\n",
      "I'm sorry, I can't help you with that. I'm built to answer Lloyds banking related questions only.\n",
      "sources used: ['Could not find relevant sources', 'Could not find relevant sources', 'Could not find relevant sources']\n",
      "scores: [0.6301180124282837, 0.5893828272819519, 0.5851236581802368]\n",
      "vector search time: 0.22679877281188965\n",
      "llm inference time: 0.518413782119751\n",
      "To set up an online banking account, you can visit your local branch or call us on 0345 300 0116. We'll need to verify your identity and then we'll be able to set up your account.\n",
      "sources used: ['https://www.lloydsbank.com/business/help-and-support/online-banking/log-on-to-o4b/memorable-information.html', 'https://www.lloydsbank.com/business/help-and-support/security-and-fraud/report-fraud-on-business-account.html?WT.ac=lloyds-bb-help_support-category-repfraud-text-report_suspected_fraud', 'https://www.lloydsbank.com/business/help-and-support/account-management/letter-of-authority.html?WT.ac=lloyds-bb-help_support-chldpage-accmgmt-text-by_email']\n",
      "scores: [0.7527010440826416, 0.7422167062759399, 0.721319317817688]\n",
      "vector search time: 0.18026065826416016\n",
      "llm inference time: 1.9115588665008545\n"
     ]
    }
   ],
   "source": [
    "rag = RAG(vai, pw)\n",
    "query = \"i've lost my card\"\n",
    "response, sources, scores, vector_search_time, lm_inference_time = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n",
    "print('vector search time:', vector_search_time)\n",
    "print('llm inference time:', lm_inference_time)\n",
    "\n",
    "query = \"why?\"\n",
    "response, sources, scores, vector_search_time, lm_inference_time = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n",
    "print('vector search time:', vector_search_time)\n",
    "print('llm inference time:', lm_inference_time)\n",
    "\n",
    "query = \"i was not asking about an audit request\"\n",
    "response, sources, score, vector_search_time, lm_inference_times = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n",
    "print('vector search time:', vector_search_time)\n",
    "print('llm inference time:', lm_inference_time)\n",
    "\n",
    "query = \"what is the weather in london\"\n",
    "response, sources, scores, vector_search_time, lm_inference_time = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n",
    "print('vector search time:', vector_search_time)\n",
    "print('llm inference time:', lm_inference_time)\n",
    "\n",
    "query = \"how can i set up an online banking account?\"\n",
    "response, sources, scores, vector_search_time, lm_inference_time = rag.generate(query)\n",
    "print(response)\n",
    "print('sources used:', sources)\n",
    "print('scores:', scores)\n",
    "print('vector search time:', vector_search_time)\n",
    "print('llm inference time:', lm_inference_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b7298fa-3852-4046-8a45-41e14ab1c7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5403467ce6f3494c9312e858b6f6c79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid bâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e62318df8e4b2faa3a7d1cacaefa70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', description='Lloyds', layout=Layout(width='80%'), placeholder='Message LBG help â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class ChatUI:\n",
    "    def __init__(self, rag_instance):\n",
    "        self.rag_instance = rag_instance\n",
    "        self.conversation = []\n",
    "        self._setup_ui()\n",
    "    \n",
    "    def _setup_ui(self):\n",
    "        self.input_box = widgets.Text(\n",
    "            placeholder='Message LBG help and support...',\n",
    "            description='Lloyds',\n",
    "            layout={'width': '80%'}\n",
    "        )\n",
    "        \n",
    "        self.send_button = widgets.Button(\n",
    "            description='Send',\n",
    "            button_style='info',\n",
    "            layout={'width': '12%'}\n",
    "        )\n",
    "        self.output_area = widgets.Output(layout={'border': '1px solid black', 'width': '100%'})\n",
    "        self.send_button.on_click(self._on_send_clicked)\n",
    "        \n",
    "        input_send_box = widgets.HBox([self.input_box, self.send_button])\n",
    "        \n",
    "        display(self.output_area, input_send_box)\n",
    "        \n",
    "    def _on_send_clicked(self, b):\n",
    "        query = self.input_box.value\n",
    "        self.conversation.append(f\"You: {query}\")\n",
    "        response = self.rag_instance.generate(query)\n",
    "        self.conversation.append(f'LBG AI: {response}')\n",
    "        \n",
    "        with self.output_area:\n",
    "            clear_output(wait=True)\n",
    "            print('\\n'.join(self.conversation))\n",
    "        \n",
    "        # clear input box\n",
    "        self.input_box.value = ''\n",
    "        \n",
    "rag = RAG(vai, pw)\n",
    "chat_ui = ChatUI(rag)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482d7de-97fb-42c0-b2ec-dfa6ced835be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
